{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A package designed for interactions with the EUtils tools from the National Library of Medicine\n",
    "\"\"\"\n",
    "import requests\n",
    "import json\n",
    "import datetime\n",
    "from enum import Enum\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import quote_plus\n",
    "from urllib.error import URLError\n",
    "from time import time,sleep\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup,Tag,Comment,NavigableString\n",
    "import pandas as pd\n",
    "\n",
    "PAGE_SIZE = 10000\n",
    "TIME_THRESHOLD = 0.3333334\n",
    "\n",
    "class NCBI_Database_Type(Enum):\n",
    "    \"\"\"\n",
    "    Supported NCBI databases within this API\n",
    "    \"\"\"\n",
    "    pubmed = 'pubmed'\n",
    "    PMC = 'PMC'\n",
    "\n",
    "class ClinicalCategory(Enum):\n",
    "    \"\"\"\n",
    "    Simple enumeration of types of clinical query\n",
    "    \"\"\"\n",
    "    NoCategory = 0\n",
    "    Diagnosis = 1\n",
    "    Therapy = 2\n",
    "    Etiology = 3\n",
    "    Prognosis = 4\n",
    "    ClinicalPrediction = 5\n",
    "\n",
    "class QueryBreadth(Enum):\n",
    "    \"\"\"\n",
    "    Simple enumeration of broad/narrow types of clinical query\n",
    "    \"\"\"\n",
    "    Unspecified = 0\n",
    "    Broad = 1\n",
    "    Narrow = 2\n",
    "\n",
    "#\n",
    "# Added Filters for Clinical Queries\n",
    "# see https://www.ncbi.nlm.nih.gov/books/NBK3827/#pubmedhelp.Clinical_Queries_Filters\n",
    "#\n",
    "BROAD_THERAPY_FILTER = '((clinical[Title/Abstract] AND trial[Title/Abstract]) OR clinical trials as topic[MeSH Terms] OR ' \\\n",
    "                'clinical trial[Publication Type] OR random*[Title/Abstract] OR random allocation[MeSH Terms] OR ' \\\n",
    "                'therapeutic use[MeSH Subheading]) AND '\n",
    "NARROW_THERAPY_FILTER = '(randomized controlled trial[Publication Type] OR (randomized[Title/Abstract] AND ' \\\n",
    "                 'controlled[Title/Abstract] AND trial[Title/Abstract])) AND '\n",
    "BROAD_DIAGNOSIS_FILTER = '(sensitiv*[Title/Abstract] OR sensitivity and specificity[MeSH Terms] OR diagnose[Title/Abstract] ' \\\n",
    "                  'OR diagnosed[Title/Abstract] OR diagnoses[Title/Abstract] OR diagnosing[Title/Abstract] OR ' \\\n",
    "                  'diagnosis[Title/Abstract] OR diagnostic[Title/Abstract] OR diagnosis[MeSH:noexp] OR diagnostic ' \\\n",
    "                  '* [MeSH:noexp] OR diagnosis,differential[MeSH:noexp] OR diagnosis[Subheading:noexp]) AND '\n",
    "NARROW_DIAGNOSIS_FILTER = '(specificity[Title/Abstract]) AND '\n",
    "BROAD_ETIOLOGY_FILTER = '(risk*[Title/Abstract] OR risk*[MeSH:noexp] OR risk *[MeSH:noexp] OR cohort studies[MeSH Terms] ' \\\n",
    "                 'OR group[Text Word] OR groups[Text Word] OR grouped [Text Word]) AND '\n",
    "NARROW_ETIOLOGY_FILTER = '((relative[Title/Abstract] AND risk*[Title/Abstract]) OR (relative risk[Text Word]) OR ' \\\n",
    "                  'risks[Text Word] OR cohort studies[MeSH:noexp] OR (cohort[Title/Abstract] AND ' \\\n",
    "                  'study[Title/Abstract]) OR (cohort[Title/Abstract] AND studies[Title/Abstract])) AND '\n",
    "BROAD_PROGNOSIS_FILTER = '(incidence[MeSH:noexp] OR mortality[MeSH Terms] OR follow up studies[MeSH:noexp] OR ' \\\n",
    "                  'prognos*[Text Word] OR predict*[Text Word] OR course*[Text Word]) AND '\n",
    "NARROW_PROGNOSIS_FILTER = '(prognos*[Title/Abstract] OR (first[Title/Abstract] AND episode[Title/Abstract]) OR ' \\\n",
    "                   'cohort[Title/Abstract]) AND '\n",
    "BROAD_CLINICAL_PREDICTION_FILTER = '(predict*[tiab] OR predictive value of tests[mh] OR score[tiab] OR scores[tiab] OR ' \\\n",
    "                            'scoring system[tiab] OR scoring systems[tiab] OR observ*[tiab] OR observer variation[mh])'\n",
    "NARROW_CLINICAL_PREDICTION_FILTER = '(validation[tiab] OR validate[tiab]) AND '\n",
    "\n",
    "class ESearchQuery:\n",
    "    \"\"\"\n",
    "    Class to provide query interface for ESearch (i.e., query terms in elaborate ways, return a list of ids)\n",
    "    Each instance of this class executes queries of a given type\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, api_key, oa=False, db='pubmed', category=ClinicalCategory.NoCategory, scope=QueryBreadth.Unspecified):\n",
    "        \"\"\"\n",
    "        Initialization of the class\n",
    "        :param query:\n",
    "        :param oa:\n",
    "        :param db:\n",
    "        :param category:\n",
    "        :param scope:\n",
    "        \"\"\"\n",
    "        self.api_key = api_key\n",
    "        self.category = category\n",
    "        self.scope = scope\n",
    "        self.idPrefix = ''\n",
    "        self.oa = oa\n",
    "        self.db = db\n",
    "\n",
    "    def execute_count_query(self, query):\n",
    "\n",
    "        if self.category == ClinicalCategory.Diagnosis and self.scope == QueryBreadth.Broad:\n",
    "            query = BROAD_DIAGNOSIS_FILTER + '(' + query + ')'\n",
    "        elif self.category == ClinicalCategory.Diagnosis and self.scope == QueryBreadth.Narrow:\n",
    "            query = NARROW_DIAGNOSIS_FILTER + '(' + query + ')'\n",
    "        elif self.category == ClinicalCategory.Therapy and self.scope == QueryBreadth.Broad:\n",
    "            query = BROAD_THERAPY_FILTER + '(' + query + ')'\n",
    "        elif self.category == ClinicalCategory.Therapy and self.scope == QueryBreadth.Narrow:\n",
    "            query = NARROW_THERAPY_FILTER + '(' + query + ')'\n",
    "        elif self.category == ClinicalCategory.Etiology and self.scope == QueryBreadth.Broad:\n",
    "            query = BROAD_ETIOLOGY_FILTER + '(' + query + ')'\n",
    "        elif self.category == ClinicalCategory.Etiology and self.scope == QueryBreadth.Narrow:\n",
    "            query = NARROW_ETIOLOGY_FILTER + '(' + query + ')'\n",
    "        elif self.category == ClinicalCategory.Prognosis and self.scope == QueryBreadth.Broad:\n",
    "            query = BROAD_PROGNOSIS_FILTER + '(' + query + ')'\n",
    "        elif self.category == ClinicalCategory.Prognosis and self.scope == QueryBreadth.Narrow:\n",
    "            query = NARROW_PROGNOSIS_FILTER + '(' + query + ')'\n",
    "        elif self.category == ClinicalCategory.ClinicalPrediction and self.scope == QueryBreadth.Broad:\n",
    "            query = BROAD_CLINICAL_PREDICTION_FILTER + '(' + query + ')'\n",
    "        elif self.category == ClinicalCategory.ClinicalPrediction and self.scope == QueryBreadth.Narrow:\n",
    "            query = NARROW_CLINICAL_PREDICTION_FILTER + '(' + query + ')'\n",
    "\n",
    "        idPrefix = ''\n",
    "        if self.oa:\n",
    "            if self.db == NCBI_Database_Type.PMC:\n",
    "                query = '\"open access\"[filter] AND (' + query + ')'\n",
    "                idPrefix = 'PMC'\n",
    "            elif self.db == NCBI_Database_Type.pubmed:\n",
    "                query = '\"loattrfree full text\"[sb] AND (' + query + ')'\n",
    "        esearch_stem = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?api_key='+self.api_key+'&db=' + self.db + '&term='\n",
    "        \n",
    "        esearch_response = urlopen(esearch_stem + query)\n",
    "        esearch_data = esearch_response.read().decode('utf-8')\n",
    "        esearch_soup = BeautifulSoup(esearch_data, \"lxml-xml\")\n",
    "        count_tag = esearch_soup.find('Count')\n",
    "        if count_tag is None:\n",
    "            raise Exception('No Data returned from \"' + self.query + '\"')\n",
    "        return int(count_tag.string)\n",
    "\n",
    "    def find_max_min_of_pmid_range_on_given_day(self, dd, min_flag=True):\n",
    "        d = dd.strftime(\"%Y/%m/%d\")\n",
    "        esearch = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?api_key='+self.api_key+'&db=pubmed&mindate=%s&maxdate=%s&datetype=edat&retmax=1'%(d,d)\n",
    "        esearch_response = urlopen(esearch)\n",
    "        esearch_data = esearch_response.read().decode('utf-8')\n",
    "        esearch_soup = BeautifulSoup(esearch_data, \"lxml-xml\")\n",
    "        count_tag = esearch_soup.find('Count')\n",
    "\n",
    "        if count_tag is None:\n",
    "            raise Exception('No Data returned from \"' + self.query + '\"')\n",
    "        count = int(count_tag.string)\n",
    "        esearch = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?api_key='+self.api_key+'&db=pubmed&mindate=%s&maxdate=%s&datetype=edat&retmax=%d'%(d,d,count)\n",
    "        esearch_response = urlopen(esearch)\n",
    "        esearch_data = esearch_response.read().decode('utf-8')\n",
    "        esearch_soup = BeautifulSoup(esearch_data, \"lxml-xml\")\n",
    "\n",
    "        pmids = sorted([int(id_tag.string) for id_tag in esearch_soup.findAll('Id')])\n",
    "\n",
    "        # find biggest block of broadly contiguous IDs with a list of lists\n",
    "        pmid_blocks = []\n",
    "        current_block = [pmids[0]]\n",
    "        pmid_blocks.append(current_block)\n",
    "        for i in range(len(pmids)-1):\n",
    "            if pmids[i+1] > pmids[i] + 10:\n",
    "                current_block = []\n",
    "                pmid_blocks.append(current_block)\n",
    "            current_block.append(pmids[i+1])\n",
    "        longest_block_length = max([len(i) for i in pmid_blocks])\n",
    "        max_min = [min(i) if min_flag else max(i) for i in pmid_blocks if len(i)==longest_block_length][0]\n",
    "\n",
    "        return max_min\n",
    "\n",
    "    def execute_query(self, query):\n",
    "\n",
    "        if self.category == ClinicalCategory.Diagnosis and self.scope == QueryBreadth.Broad:\n",
    "            query = BROAD_DIAGNOSIS_FILTER + '(' + query + ')'\n",
    "        elif self.category == ClinicalCategory.Diagnosis and self.scope == QueryBreadth.Narrow:\n",
    "            query = NARROW_DIAGNOSIS_FILTER + '(' + query + ')'\n",
    "        elif self.category == ClinicalCategory.Therapy and self.scope == QueryBreadth.Broad:\n",
    "            query = BROAD_THERAPY_FILTER + '(' + query + ')'\n",
    "        elif self.category == ClinicalCategory.Therapy and self.scope == QueryBreadth.Narrow:\n",
    "            query = NARROW_THERAPY_FILTER + '(' + query + ')'\n",
    "        elif self.category == ClinicalCategory.Etiology and self.scope == QueryBreadth.Broad:\n",
    "            query = BROAD_ETIOLOGY_FILTER + '(' + query + ')'\n",
    "        elif self.category == ClinicalCategory.Etiology and self.scope == QueryBreadth.Narrow:\n",
    "            query = NARROW_ETIOLOGY_FILTER + '(' + query + ')'\n",
    "        elif self.category == ClinicalCategory.Prognosis and self.scope == QueryBreadth.Broad:\n",
    "            query = BROAD_PROGNOSIS_FILTER + '(' + query + ')'\n",
    "        elif self.category == ClinicalCategory.Prognosis and self.scope == QueryBreadth.Narrow:\n",
    "            query = NARROW_PROGNOSIS_FILTER + '(' + query + ')'\n",
    "        elif self.category == ClinicalCategory.ClinicalPrediction and self.scope == QueryBreadth.Broad:\n",
    "            query = BROAD_CLINICAL_PREDICTION_FILTER + '(' + query + ')'\n",
    "        elif self.category == ClinicalCategory.ClinicalPrediction and self.scope == QueryBreadth.Narrow:\n",
    "            query = NARROW_CLINICAL_PREDICTION_FILTER + '(' + query + ')'\n",
    "\n",
    "        idPrefix = ''\n",
    "        if self.oa:\n",
    "            if self.db == NCBI_Database_Type.PMC:\n",
    "                query = '\"open access\"[filter] AND (' + query + ')'\n",
    "                idPrefix = 'PMC'\n",
    "            elif self.db == NCBI_Database_Type.pubmed:\n",
    "                query = '\"loattrfree full text\"[sb] AND (' + query + ')'\n",
    "        esearch_stem = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?api_key='+self.api_key+'&db=' + self.db + '&term='\n",
    "        #query = quote_plus(query)\n",
    "        print(esearch_stem + query)\n",
    "        esearch_response = urlopen(esearch_stem + query)\n",
    "        esearch_data = esearch_response.read().decode('utf-8')\n",
    "        esearch_soup = BeautifulSoup(esearch_data, \"lxml-xml\")\n",
    "        count_tag = esearch_soup.find('Count')\n",
    "        if count_tag is None:\n",
    "            raise Exception('No Data returned from \"' + query + '\"')\n",
    "        count = int(count_tag.string)\n",
    "\n",
    "        latest_time = time()\n",
    "\n",
    "        ids = []\n",
    "        for i in tqdm(range(0,count,PAGE_SIZE)):\n",
    "            full_query = esearch_stem + query + '&retstart=' + str(i)+ '&retmax=' + str(PAGE_SIZE)\n",
    "            esearch_response = urlopen(full_query)\n",
    "            esearch_data = esearch_response.read().decode('utf-8')\n",
    "            esearch_soup = BeautifulSoup(esearch_data, \"lxml-xml\")\n",
    "            for pmid_tag in esearch_soup.find_all('Id') :\n",
    "                ids.append(self.idPrefix + pmid_tag.text)\n",
    "            delta_time = time() - latest_time\n",
    "            if delta_time < TIME_THRESHOLD :\n",
    "                sleep(TIME_THRESHOLD - delta_time)\n",
    "\n",
    "        return ids\n",
    "\n",
    "class EFetchQuery:\n",
    "    \"\"\"\n",
    "    Class to provide query interface for ESearch (i.e., query terms in elaborate ways, return a list of ids)\n",
    "    Each instance of this class executes queries of a given type\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, oa=False, db='pubmed'):\n",
    "        \"\"\"\n",
    "        Initialization of the class\n",
    "        :param query:\n",
    "        :param oa:\n",
    "        :param db:\n",
    "        \"\"\"\n",
    "        self.oa = oa\n",
    "        self.db = db\n",
    "\n",
    "    def execute_efetch(self, pmid):\n",
    "        efetch_stem = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pubmed&retmode=xml&id='\n",
    "        efetch_response = urlopen(efetch_stem + str(pmid))\n",
    "        return self._generate_rows_from_medline_records(efetch_response.read().decode('utf-8'))\n",
    "\n",
    "    def generate_data_frame_from_id_list(self, id_list):\n",
    "\n",
    "        efetch_stem = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pubmed&retmode=xml&id='\n",
    "\n",
    "        page_size = 100\n",
    "        i = 0\n",
    "        url = efetch_stem\n",
    "        efetch_df = pd.DataFrame()\n",
    "        for line in tqdm(id_list):\n",
    "            try:\n",
    "                l = re.split('\\s+', str(line))\n",
    "                pmid = l[0]\n",
    "                i += 1\n",
    "                if i >= page_size:\n",
    "                    efetch_response = urlopen(url)\n",
    "                    df = self._generate_rows_from_medline_records(efetch_response.read().decode('utf-8'))\n",
    "                    efetch_df = efetch_df.append(df)\n",
    "                    url = efetch_stem\n",
    "                    i = 0\n",
    "\n",
    "                if re.search('\\d$', url):\n",
    "                    url += ','\n",
    "                url += pmid.strip()\n",
    "            except URLError as e:\n",
    "                sleep(10)\n",
    "                print(\"URLError({0}): {1}\".format(e.errno, e.strerror))\n",
    "            except TypeError as e2:\n",
    "                pause = 1\n",
    "\n",
    "        if url != efetch_stem:\n",
    "            efetch_response = urlopen(url)\n",
    "            df = self._generate_rows_from_medline_records(efetch_response.read().decode('utf-8'))\n",
    "            efetch_df = efetch_df.append(df)\n",
    "        return efetch_df\n",
    "\n",
    "    def generate_mesh_data_frame_from_id_list(self, id_list):\n",
    "\n",
    "        url = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi'\n",
    "        payload = 'db=pubmed&retmode=xml&id='\n",
    "        headers = {'content-type': 'application/xml'}\n",
    "\n",
    "        page_size = 10000\n",
    "        i = 0\n",
    "        efetch_df = pd.DataFrame()\n",
    "        for line in tqdm(id_list):\n",
    "            try:\n",
    "                l = re.split('\\s+', line)\n",
    "                pmid = l[0]\n",
    "                i += 1\n",
    "                if i >= page_size:\n",
    "                    print('   running query')\n",
    "                    r = requests.post(url, data=payload)\n",
    "                    efetch_data = r.content.decode('utf-8')\n",
    "                    df = self._generate_mesh_rows_from_medline_records(efetch_data)\n",
    "                    efetch_df = efetch_df.append(df)\n",
    "                    payload = 'db=pubmed&retmode=xml&id='\n",
    "                    i = 0\n",
    "\n",
    "                if re.search('\\d$', payload):\n",
    "                    payload += ','\n",
    "                payload += pmid.strip()\n",
    "            except URLError as e:\n",
    "                sleep(10)\n",
    "                print(\"URLError({0}): {1}\".format(e.errno, e.strerror))\n",
    "\n",
    "        if payload[-1] != '=':\n",
    "            r = requests.post(url, data=payload)\n",
    "            efetch_data = r.content.decode('utf-8')\n",
    "            df = self._generate_mesh_rows_from_medline_records(efetch_data)\n",
    "            efetch_df = efetch_df.append(df)\n",
    "\n",
    "        return efetch_df\n",
    "\n",
    "    def _generate_mesh_rows_from_medline_records(self, record):\n",
    "\n",
    "        soup2 = BeautifulSoup(record, \"lxml-xml\")\n",
    "\n",
    "        rows = []\n",
    "        cols = ['PMID','MESH']\n",
    "        for citation_tag in tqdm(soup2.find_all('MedlineCitation')):\n",
    "\n",
    "            pmid_tag = citation_tag.find('PMID')\n",
    "\n",
    "            mesh_labels = []\n",
    "\n",
    "            if pmid_tag is None:\n",
    "                continue\n",
    "\n",
    "            for meshTag in citation_tag.findAll('MeshHeading'):\n",
    "                desc = meshTag.find('DescriptorName')\n",
    "                qual_list = meshTag.findAll('QualifierName')\n",
    "                if len(qual_list)>0:\n",
    "                    mesh_labels.append('%s/%s'%(desc.text.replace('\\n', ' '),'/'.join(q.text.replace('\\n', ' ') for q in qual_list)))\n",
    "                else:\n",
    "                    mesh_labels.append(desc.text.replace('\\n', ' '))\n",
    "            mesh_data = \",\".join(mesh_labels)\n",
    "\n",
    "            rows.append((pmid_tag.text, mesh_data))\n",
    "\n",
    "        df = pd.DataFrame(data=rows, columns=cols)\n",
    "        return df\n",
    "\n",
    "    def _generate_rows_from_medline_records(self, record):\n",
    "\n",
    "        soup2 = BeautifulSoup(record, \"lxml-xml\")\n",
    "\n",
    "        rows = []\n",
    "        cols = ['PMID', 'YEAR', 'PUBLICATION_TYPE', 'TITLE', 'ABSTRACT','MESH','KEYWORDS']\n",
    "        for citation_tag in soup2.find_all('MedlineCitation'):\n",
    "\n",
    "            pmid_tag = citation_tag.find('PMID')\n",
    "            title_tag = citation_tag.find('ArticleTitle')\n",
    "            abstract_txt = ''\n",
    "            for x in citation_tag.findAll('AbstractText'):\n",
    "                if x.label is not None:\n",
    "                    abstract_txt += ' ' + x.label + ': '\n",
    "                abstract_txt += x.text\n",
    "\n",
    "            mesh_labels = []\n",
    "            for meshTag in citation_tag.findAll('MeshHeading'):\n",
    "                desc = meshTag.find('DescriptorName')\n",
    "                qual_list = meshTag.findAll('QualifierName')\n",
    "                if len(qual_list)>0:\n",
    "                    mesh_labels.append('%s/%s'%(desc.text.replace('\\n', ' '),'/'.join(q.text.replace('\\n', ' ') for q in qual_list)))\n",
    "                else:\n",
    "                    mesh_labels.append(desc.text.replace('\\n', ' '))\n",
    "            mesh_data = \",\".join(mesh_labels)\n",
    "\n",
    "            if pmid_tag is None or title_tag is None or abstract_txt == '':\n",
    "                continue\n",
    "\n",
    "            year_tag = citation_tag.find('PubDate').find('Year')\n",
    "\n",
    "            year = ''\n",
    "            if year_tag is not None:\n",
    "                year = year_tag.text\n",
    "\n",
    "            is_review = '|'.join([x.text for x in citation_tag.findAll('PublicationType')])\n",
    "\n",
    "            keyword_data = '|'.join([meshTag.text.replace('\\n', ' ') for meshTag in citation_tag.findAll('Keyword')])\n",
    "\n",
    "            rows.append((pmid_tag.text, year, is_review, title_tag.text, abstract_txt, mesh_data, keyword_data))\n",
    "\n",
    "        df = pd.DataFrame(data=rows, columns=cols)\n",
    "        return df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
